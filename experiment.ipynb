{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c321c87b-3f21-4577-95c9-a4afbb9bcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./common_lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3521fe18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from munch import Munch  # Munch is a dictionary that supports attribute-style access\n",
    "\n",
    "config_names = [\n",
    "    \"mini\",\n",
    "    # \"tiny\",\n",
    "    # 'small',\n",
    "    # 'medium',\n",
    "    # 'large',\n",
    "    # 'XL',\n",
    "]\n",
    "\n",
    "\n",
    "def add_exp_name(config):\n",
    "    \"\"\"Constructs the name of the log folder used to easily identify the experiment.\"\"\"\n",
    "    c = config\n",
    "    c.exp_name = \"{}_{}_{}_sl{}_h{}_ff{}_nH{}_dH{}_nl{}_seed{}{}{}\".format(\n",
    "        c.model,\n",
    "        f\"_bl{c.block_length}\",\n",
    "        c.dataset,\n",
    "        c.seq_len,\n",
    "        c.h_dim,\n",
    "        c.mlp_dim,\n",
    "        c.n_heads,\n",
    "        c.head_dim,\n",
    "        c.n_layers,\n",
    "        c.seed,\n",
    "        f\"_{c.comment}\" if c.comment else \"\",\n",
    "        \"_debug\" if c.debug else \"\",\n",
    "    )\n",
    "\n",
    "\n",
    "## Add experiment configs\n",
    "def load_config(name=None):\n",
    "\n",
    "    c = Munch(\n",
    "        # # data\n",
    "        # data_root = \"data/books\",\n",
    "        relative_log_path=\"logs\",  # Relative path to the log folder within the project folder\n",
    "        # dataset = \"books_16384\",\n",
    "        # vocab_size = 16384,\n",
    "        debug=False,  # simply adds a \"_debug\" suffix so logs are easily distinguishable\n",
    "        # # optimiser\n",
    "        seed=41,\n",
    "        # gradient_accumulation_steps = 1,    # number of batches before doing a gradient step\n",
    "        train_batch_size=32,  # make sure batch sizes are an integer multiple of the number of workers\n",
    "        eval_batch_size=32,\n",
    "        test_batch_size=32,\n",
    "        # seq_len = 512,\n",
    "        # max_eval_steps = 512,\n",
    "        # max_train_steps = 500_000,          # total number of training steps\n",
    "        # decay_steps = 500_000,              # number of steps over which we will decay the learning rate\n",
    "        # max_lr = 0.0006,                    # starting learning rate\n",
    "        # min_lr = 0.000006,                  # final learning rate\n",
    "        # grad_clip_norm = 0.0,               # gradient norm clipping\n",
    "        # tokens_per_second = 0,              # tokens per second throughput of this config on the hardware run; used for logging over gpuhours\n",
    "        # # perform certain tasks every N steps\n",
    "        # eval_every = 1_000,                 # perform a fast evaluation (validation data)\n",
    "        # test_every = -1,                    # perform a thorough evaluation (test data)\n",
    "        # log_terminal_every = 100,           # print the current loss to terminal\n",
    "        # log_metrics_every = 100,            # log accuracy and loss metrics\n",
    "        # log_grads_every = 1_000,            # log gradients and step sizes\n",
    "        # log_activations_every = -1,         # log gradients and step sizes\n",
    "        log_ckpt_every=1_000,  # save model checkpoint to disk\n",
    "        # logging\n",
    "        comment=\"\",\n",
    "        logger_type=\"wandb\",  # can be 'tb', 'wandb' or 'all'\n",
    "        wandb_project_name=\"qlstm\",\n",
    "        dataset=\"bit_parity\", #[\"bit_parity\", \"dyck\", \"mqar\"]\n",
    "        model=\"gpt\", #[\"lstm\", \"qlstm\", \"gpt\", \"linear_transfomer\", \"lru\", \"delta_net\", \"mamba\"]\n",
    "        project_name=\"associative_rnns\",\n",
    "        max_steps = 40000,\n",
    "        use_flash = False\n",
    "    )\n",
    "    # default model\n",
    "    if not name or name == \"default\":\n",
    "        name = \"mini\"\n",
    "\n",
    "    # model\n",
    "    if name == \"mini\":\n",
    "        c.n_layers = 2\n",
    "        c.h_dim = 4\n",
    "        c.mlp_dim = 8\n",
    "        c.head_dim = 4\n",
    "        c.n_heads = 4\n",
    "        c.block_length = 8 # keep it equal to seq len for faster convergence\n",
    "\n",
    "        # Mamba\n",
    "        c.d_model = 128\n",
    "        c.d_state = 8\n",
    "        c.d_conv = 3\n",
    "        c.expand = 2\n",
    "        c.dt_rank = 1\n",
    "\n",
    "        # Dataset config\n",
    "        c.output_size = 2\n",
    "        c.num_input_classes = 2\n",
    "\n",
    "        # Dyck specific\n",
    "        c.depth = 6\n",
    "        c.num_parentheses = 3\n",
    "        c.seq_len = 8\n",
    "\n",
    "        #MQAR specific\n",
    "        c.n_keys = 3\n",
    "        c.n_values = 6\n",
    "        c.train_num_pairs = \"3,3\"\n",
    "        c.eval_num_pairs = \"3,3\"\n",
    "        c.max_num_pairs = 3\n",
    "        c.unique_keys = True\n",
    "        c.all_queries_for_input = False\n",
    "\n",
    "        # Bit parity specific\n",
    "        c.train_seq_len = \"8,8\"\n",
    "        c.eval_seq_len = \"8,8\"\n",
    "        c.num_ones = None\n",
    "        c.max_seq_len = 8\n",
    "    else:\n",
    "        raise ValueError(f\"Config name {name} is an invalid name. \")\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b807a303-6cf8-4124-ba33-6b7bb5660230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.bit_parity_dataset import BitParityDatasetIterator\n",
    "from datasets.dyck_dataset import DyckDatasetIterator\n",
    "from datasets.mqar_dataset import MQARDatasetIterator\n",
    "\n",
    "def construct_dataset(config):\n",
    "    if config.dataset == \"bit_parity\":\n",
    "        train_ds = BitParityDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            sequence_length=config.train_seq_len,\n",
    "            num_ones=config.num_ones,\n",
    "            device=config.device,\n",
    "        )\n",
    "        eval_ds = BitParityDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            sequence_length=config.eval_seq_len,\n",
    "            num_ones=config.num_ones,\n",
    "            device=config.device,\n",
    "        )\n",
    "    elif config.dataset == \"dyck\":\n",
    "        train_ds = DyckDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            sequence_length=config.train_seq_len,\n",
    "            device=config.device,\n",
    "            depth=config.depth,\n",
    "            num_parentheses=config.num_parentheses,\n",
    "        )\n",
    "        eval_ds = DyckDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            sequence_length=config.eval_seq_len,\n",
    "            device=config.device,\n",
    "            depth=config.depth,\n",
    "            num_parentheses=config.num_parentheses,\n",
    "        )\n",
    "        config.num_input_classes = config.num_parentheses * 2 + 2\n",
    "    elif config.dataset == \"mqar\":\n",
    "        train_ds = MQARDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            num_pairs=config.train_num_pairs,\n",
    "            n_keys=config.n_keys,\n",
    "            n_values=config.n_values,\n",
    "            unique_keys=config.unique_keys,\n",
    "            all_queries_for_input=config.all_queries_for_input,\n",
    "            device=config.device,\n",
    "        )\n",
    "        eval_ds = MQARDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            num_pairs=config.eval_num_pairs,\n",
    "            n_keys=config.n_keys,\n",
    "            n_values=config.n_values,\n",
    "            unique_keys=config.unique_keys,\n",
    "            all_queries_for_input=config.all_queries_for_input,\n",
    "            device=config.device,\n",
    "        )\n",
    "        config.num_input_classes = max(config.n_keys, config.n_values + 1) + 1\n",
    "        config.output_size = config.n_values + 1\n",
    "        config.max_seq_len = max(config.max_num_pairs * 3, config.max_seq_len)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset {config.dataset} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "        \n",
    "    return train_ds, eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33dd22a-e250-4d5b-9c95-bd88d8ea0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.bit_parity_trainer import BitParityTrainer\n",
    "from trainers.dyck_trainer import DyckTrainer\n",
    "from trainers.mqar_trainer import MQARTrainer\n",
    "\n",
    "def construct_trainerClass(config):\n",
    "    if config.dataset == \"bit_parity\":\n",
    "        trainer = BitParityTrainer\n",
    "    elif config.dataset == \"dyck\":\n",
    "        trainer = DyckTrainer\n",
    "    elif config.dataset == \"mqar\":\n",
    "        trainer.dataset = MQARTrainer\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset {config.dataset} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80586e71-380c-417d-861d-d0a321376f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0 active drivers ([]). There should only be one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlru\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodellru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelLRU\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeltanet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelDeltanet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelDeltaNet\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelmamba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMamba\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconstruct_model\u001b[39m(config):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/modern_rnns/projects/mamba/modelmamba.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# --- Import MambaBlock and LayerNorm from lib.py ---\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mprojects\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MambaBlock, LayerNorm\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmprint\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/modern_rnns/projects/mamba/lib.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# --- Optional Mamba Imports (Attempt, but fallback included) ---\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselective_scan_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m selective_scan_fn, mamba_inner_fn\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     selective_scan_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mamba/mamba_ssm/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.2.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselective_scan_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m selective_scan_fn, mamba_inner_fn\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba_simple\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mamba\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmamba2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mamba2\n",
      "File \u001b[0;32m~/mamba/mamba_ssm/ops/selective_scan_interface.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m     causal_conv1d_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     causal_conv1d_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_norm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _layer_norm_fwd\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselective_scan_cuda\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSelectiveScanFn\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mFunction):\n",
      "File \u001b[0;32m~/mamba/mamba_ssm/ops/triton/layer_norm.py:179\u001b[0m\n\u001b[1;32m    158\u001b[0m configs_autotune \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    159\u001b[0m         triton\u001b[38;5;241m.\u001b[39mConfig({}, num_warps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    160\u001b[0m         triton\u001b[38;5;241m.\u001b[39mConfig({}, num_warps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         triton\u001b[38;5;241m.\u001b[39mConfig({}, num_warps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m),\n\u001b[1;32m    165\u001b[0m         ]\n\u001b[1;32m    167\u001b[0m pruned_configs_autotune \u001b[38;5;241m=\u001b[39m config_prune(configs_autotune)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautotune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpruned_configs_autotune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHAS_RESIDUAL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTORE_RESIDUAL_OUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIS_RMS_NORM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHAS_BIAS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;43;03m# @triton.heuristics({\"HAS_BIAS\": lambda args: args[\"B\"] is not None})\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;43;03m# @triton.heuristics({\"HAS_RESIDUAL\": lambda args: args[\"RESIDUAL\"] is not None})\u001b[39;49;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheuristics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHAS_X1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheuristics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHAS_W1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheuristics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHAS_B1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;129;43m@triton\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43m_layer_norm_fwd_1pass_kernel\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the input\u001b[39;49;00m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the output\u001b[39;49;00m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the weights\u001b[39;49;00m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the biases\u001b[39;49;00m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRESIDUAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the residual\u001b[39;49;00m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mB1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRESIDUAL_OUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the residual\u001b[39;49;00m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mROWSCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSEEDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dropout seeds for each row\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDROPOUT_MASK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the mean\u001b[39;49;00m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pointer to the 1/std\u001b[39;49;00m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_x_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# how much to increase the pointer when moving by 1 row\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_y_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_res_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_res_out_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_x1_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_y1_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# number of rows in X\u001b[39;49;00m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# number of columns in X\u001b[39;49;00m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# epsilon to avoid division by zero\u001b[39;49;00m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dropout probability\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIS_RMS_NORM\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBLOCK_N\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_RESIDUAL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSTORE_RESIDUAL_OUT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_BIAS\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_DROPOUT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSTORE_DROPOUT_MASK\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_ROWSCALE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_X1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_W1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHAS_B1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstexpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Map the program id to the row of X and Y it should compute.\u001b[39;49;00m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogram_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride_x_row\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cil/lib/python3.10/site-packages/triton/runtime/autotuner.py:378\u001b[0m, in \u001b[0;36mautotune.<locals>.decorator\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorator\u001b[39m(fn):\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAutotuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_to_zero\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpost_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprune_configs_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprune_configs_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                     \u001b[49m\u001b[43muse_cuda_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cuda_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_bench\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_bench\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cil/lib/python3.10/site-packages/triton/runtime/autotuner.py:130\u001b[0m, in \u001b[0;36mAutotuner.__init__\u001b[0;34m(self, fn, arg_names, configs, key, reset_to_zero, restore_value, pre_hook, post_hook, prune_configs_by, warmup, rep, use_cuda_graph, do_bench)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_bench \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_bench \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_benchmarker\u001b[49m()\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_bench \u001b[38;5;241m=\u001b[39m do_bench\n",
      "File \u001b[0;32m~/miniconda3/envs/cil/lib/python3.10/site-packages/triton/runtime/driver.py:23\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/cil/lib/python3.10/site-packages/triton/runtime/driver.py:20\u001b[0m, in \u001b[0;36mLazyProxy._initialize_obj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cil/lib/python3.10/site-packages/triton/runtime/driver.py:8\u001b[0m, in \u001b[0;36m_create_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m actives \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mdriver \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m backends\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mis_active()]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actives) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(actives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactives\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). There should only be one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m actives[\u001b[38;5;241m0\u001b[39m]()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0 active drivers ([]). There should only be one."
     ]
    }
   ],
   "source": [
    "from projects.gpt.modelgpt import ModelGPT\n",
    "from projects.lstm.modellstm import ModelLSTM\n",
    "from projects.qlstm.modelqlstm import ModelQLSTM\n",
    "from projects.linearTransformer.modelLinTransformer import ModelLinTransformer\n",
    "from projects.lru.modellru import ModelLRU\n",
    "from projects.deltanet.modelDeltanet import ModelDeltaNet\n",
    "from projects.mamba.modelmamba import ModelMamba\n",
    "\n",
    "def construct_model(config):\n",
    "    if config.model == \"gpt\":\n",
    "        model = ModelGPT(config = config)\n",
    "    elif config.model == \"lstm\":\n",
    "        model = ModelLSTM(config = config)\n",
    "    elif config.model == \"qlstm\":\n",
    "        model = ModelQLSTM(config = config)\n",
    "    elif config.model == \"lin_transformer\":\n",
    "        model = ModelLinTransformer(config = config)\n",
    "    elif config.model == \"lru\":\n",
    "        model = ModelLRU(config = config)\n",
    "    elif config.model == \"delta_net\":\n",
    "        model = ModelDeltaNet(config = config)\n",
    "    elif config.model == \"mamba\":\n",
    "        model = ModelMamba(config = config)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Model {config.model} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc81df0-9786-4ab6-bf8e-f9fd03dc3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def set_up_seeds(config):\n",
    "    torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb5d10fd-df72-4dad-b1ee-09d695583b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config):\n",
    "    \n",
    "    set_up_seeds(config)\n",
    "    train_ds, eval_ds = construct_dataset(config)\n",
    "    trainerClass = construct_trainerClass(config)\n",
    "    model = construct_model(config).to(config.device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.95), eps=1e-08)\n",
    "    logger = experiment_utils.setup_experiment(config)\n",
    "    \n",
    "    trainer = trainerClass(\n",
    "        config=config,\n",
    "        model=model,\n",
    "        train_loader=train_ds,\n",
    "        eval_loader=eval_ds,\n",
    "        optimizer=opt,\n",
    "        device=config.device,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c294b550-4913-4b78-b714-8edd3ca247e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wrapper(config):\n",
    "    import sys, os\n",
    "    sys.path.append('./common_lib')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        config.device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        mprint(\"Cuda is not available, using CPU instead.\")\n",
    "        config.device = torch.device(\"cpu\")\n",
    "    config.project_path = os.path.join(os.getcwd(), 'projects', config.model)\n",
    "    add_exp_name(config)\n",
    "    print(config.dataset, config.model, config.train_seq_len, config.eval_seq_len)\n",
    "    #config.run_name = f\"{config.model}_{config.dataset}_par_{config.num_parentheses}_depth_{config.depth}_{config.train_seq_len}_{config.eval_seq_len}\"\n",
    "    config.run_name = f\"{config.model}_{config.dataset}_{config.train_seq_len}_{config.eval_seq_len}\"\n",
    "    \n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "    wandb.init(project=config.project_name, entity=\"www-vickyzeu\", config=config, name = config.run_name)\n",
    "    return run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c08d31d-3292-466d-93fa-bfa600980529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "import wandb\n",
    "from common_lib import experiment_utils\n",
    "\n",
    "train_seq_lens = [f\"{x},{x}\" for x in [2 ** i for i in range(3, 9)]]\n",
    "eval_seq_lens = [f\"{x},{x}\" for x in [2 ** i + 2 ** (i - 1) for i in range(3, 9)]]\n",
    "models = [\"lstm\", \"gpt\", \"qlstm\", \"lin_transformer\", \"lru\", \"delta_net\", \"mamba\"]\n",
    "\n",
    "def train(local=False):\n",
    "    config = load_config()\n",
    "    if local:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "\n",
    "        run(config)\n",
    "    else:\n",
    "        executor = submitit.AutoExecutor(folder=\"logs/slurm\")\n",
    "        executor.update_parameters(\n",
    "            timeout_min=60*6,\n",
    "            tasks_per_node=1,\n",
    "            #cpus_per_task=4,\n",
    "            account=\"pmlr_jobs\",\n",
    "            name=\"pmlr_training\"\n",
    "        )\n",
    "        jobs = []\n",
    "        for train_seq_len, eval_seq_len in zip(train_seq_lens[:1], eval_seq_lens[:1]):\n",
    "            for model in models[6:7]:\n",
    "                config.train_seq_len = train_seq_len\n",
    "                config.eval_seq_len = eval_seq_len\n",
    "                config.max_seq_len = max(int(train_seq_len.split(',')[-1]), int(eval_seq_len.split(',')[-1]))\n",
    "                config.model = model\n",
    "                config.block_length = min(8, config.max_seq_len)\n",
    "                jobs.append(executor.submit(run_wrapper, config))\n",
    "                \n",
    "        print(f\"Submitted {len(jobs)} jobs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae4bb5b-c1d2-4e79-963a-072c9aafa27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted 1 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vzarzu/miniconda3/envs/cil/lib/python3.10/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'account' is deprecated. Use 'slurm_account' instead.\n",
      "  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "env_path = os.path.join('.', '.env')  # won't work in Jupyter\n",
    "load_dotenv()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87c21b-380f-4d1b-895a-ff9721e572bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
