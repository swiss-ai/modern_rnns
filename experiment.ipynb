{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c321c87b-3f21-4577-95c9-a4afbb9bcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./common_lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3521fe18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from munch import Munch  # Munch is a dictionary that supports attribute-style access\n",
    "\n",
    "config_names = [\n",
    "    \"mini\",\n",
    "    # \"tiny\",\n",
    "    # 'small',\n",
    "    # 'medium',\n",
    "    # 'large',\n",
    "    # 'XL',\n",
    "]\n",
    "\n",
    "\n",
    "def add_exp_name(config):\n",
    "    \"\"\"Constructs the name of the log folder used to easily identify the experiment.\"\"\"\n",
    "    c = config\n",
    "    c.exp_name = \"{}LSTM{}_{}_sl{}_h{}_ff{}_nH{}_dH{}_nl{}_seed{}{}{}\".format(\n",
    "        \"quasi\",\n",
    "        f\"_bl{c.block_length}\",\n",
    "        c.dataset,\n",
    "        c.seq_len,\n",
    "        c.h_dim,\n",
    "        c.mlp_dim,\n",
    "        c.n_heads,\n",
    "        c.head_dim,\n",
    "        c.n_layers,\n",
    "        c.seed,\n",
    "        f\"_{c.comment}\" if c.comment else \"\",\n",
    "        \"_debug\" if c.debug else \"\",\n",
    "    )\n",
    "\n",
    "\n",
    "## Add experiment configs\n",
    "def load_config(name=None):\n",
    "\n",
    "    c = Munch(\n",
    "        # # data\n",
    "        # data_root = \"data/books\",\n",
    "        relative_log_path=\"logs\",  # Relative path to the log folder within the project folder\n",
    "        # dataset = \"books_16384\",\n",
    "        # vocab_size = 16384,\n",
    "        debug=False,  # simply adds a \"_debug\" suffix so logs are easily distinguishable\n",
    "        # # optimiser\n",
    "        seed=41,\n",
    "        # gradient_accumulation_steps = 1,    # number of batches before doing a gradient step\n",
    "        train_batch_size=1,  # make sure batch sizes are an integer multiple of the number of workers\n",
    "        eval_batch_size=1,\n",
    "        test_batch_size=1,\n",
    "        # seq_len = 512,\n",
    "        # max_eval_steps = 512,\n",
    "        # max_train_steps = 500_000,          # total number of training steps\n",
    "        # decay_steps = 500_000,              # number of steps over which we will decay the learning rate\n",
    "        # max_lr = 0.0006,                    # starting learning rate\n",
    "        # min_lr = 0.000006,                  # final learning rate\n",
    "        # grad_clip_norm = 0.0,               # gradient norm clipping\n",
    "        # tokens_per_second = 0,              # tokens per second throughput of this config on the hardware run; used for logging over gpuhours\n",
    "        # # perform certain tasks every N steps\n",
    "        # eval_every = 1_000,                 # perform a fast evaluation (validation data)\n",
    "        # test_every = -1,                    # perform a thorough evaluation (test data)\n",
    "        # log_terminal_every = 100,           # print the current loss to terminal\n",
    "        # log_metrics_every = 100,            # log accuracy and loss metrics\n",
    "        # log_grads_every = 1_000,            # log gradients and step sizes\n",
    "        # log_activations_every = -1,         # log gradients and step sizes\n",
    "        log_ckpt_every=1_000,  # save model checkpoint to disk\n",
    "        # logging\n",
    "        comment=\"\",\n",
    "        logger_type=\"wandb\",  # can be 'tb', 'wandb' or 'all'\n",
    "        wandb_project_name=\"qlstm\",\n",
    "        dataset=\"bit_parity\", #[\"bit_parity\", \"dyck\", \"mqar\"]\n",
    "        model=\"lstm\" #[\"lstm\", \"qlstm\", \"gpt\"]\n",
    "    )\n",
    "    # default model\n",
    "    if not name or name == \"default\":\n",
    "        name = \"mini\"\n",
    "\n",
    "    # model\n",
    "    if name == \"mini\":\n",
    "        c.n_layers = 2\n",
    "        c.h_dim = 4\n",
    "        c.mlp_dim = 8\n",
    "        c.head_dim = 4\n",
    "        c.n_heads = 4\n",
    "        c.block_length = 8 # keep it equal to seq len for faster convergence\n",
    "\n",
    "        # Dataset config\n",
    "        c.output_size = 2\n",
    "        c.num_input_classes = 2\n",
    "\n",
    "        # Dyck specific\n",
    "        c.depth = 3\n",
    "        c.num_parentheses = 4\n",
    "        c.seq_len = 8\n",
    "\n",
    "        #MQAR specific\n",
    "        c.n_keys = 3\n",
    "        c.n_values = 6\n",
    "        c.train_num_pairs = \"3,3\"\n",
    "        c.eval_num_pairs = \"3,3\"\n",
    "        c.max_num_pairs = 3\n",
    "        c.unique_keys = True\n",
    "        c.all_queries_for_input = False\n",
    "\n",
    "        # Bit parity specific\n",
    "        c.train_seq_len = \"8,8\"\n",
    "        c.eval_seq_len = \"8,8\"\n",
    "        c.max_seq_len = 8\n",
    "    else:\n",
    "        raise ValueError(f\"Config name {name} is an invalid name. \")\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b807a303-6cf8-4124-ba33-6b7bb5660230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.bit_parity_dataset import BitParityDatasetIterator\n",
    "from datasets.dyck_dataset import DyckDatasetIterator\n",
    "from datasets.mqar_dataset import MQARDatasetIterator\n",
    "\n",
    "def construct_dataset(config):\n",
    "    if config.dataset == \"bit_parity\":\n",
    "        train_ds = BitParityDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            sequence_length=config.train_seq_len,\n",
    "            pad_sequence_length=config.max_seq_len,\n",
    "            device=config.device,\n",
    "        )\n",
    "        eval_ds = BitParityDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            sequence_length=config.eval_seq_len,\n",
    "            pad_sequence_length=config.max_seq_len,\n",
    "            device=config.device,\n",
    "        )\n",
    "    elif config.dataset == \"dyck\":\n",
    "        train_ds = DyckDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            sequence_length=config.train_seq_len,\n",
    "            pad_sequence_length=config.max_seq_len,\n",
    "            device=config.device,\n",
    "            depth=config.depth,\n",
    "            num_parentheses=config.num_parentheses,\n",
    "        )\n",
    "        eval_ds = DyckDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            sequence_length=config.eval_seq_len,\n",
    "            pad_sequence_length=config.max_seq_len,\n",
    "            device=config.device,\n",
    "            depth=config.depth,\n",
    "            num_parentheses=config.num_parentheses,\n",
    "        )\n",
    "        config.num_input_classes = config.num_parentheses * 2 + 1\n",
    "    elif config.dataset == \"mqar\":\n",
    "        train_ds = MQARDatasetIterator(\n",
    "            batch_size=config.train_batch_size,\n",
    "            num_pairs=config.train_num_pairs,\n",
    "            n_keys=config.n_keys,\n",
    "            n_values=config.n_values,\n",
    "            pad_num_pairs=config.max_num_pairs,\n",
    "            unique_keys=config.unique_keys,\n",
    "            all_queries_for_input=config.all_queries_for_input,\n",
    "            device=config.device,\n",
    "        )\n",
    "        eval_ds = MQARDatasetIterator(\n",
    "            batch_size=config.eval_batch_size,\n",
    "            num_pairs=config.eval_num_pairs,\n",
    "            n_keys=config.n_keys,\n",
    "            n_values=config.n_values,\n",
    "            pad_num_pairs=config.max_num_pairs,\n",
    "            unique_keys=config.unique_keys,\n",
    "            all_queries_for_input=config.all_queries_for_input,\n",
    "            device=config.device,\n",
    "        )\n",
    "        config.num_input_classes = max(config.n_keys, config.n_values + 1) + 1\n",
    "        config.output_size = config.n_values + 1\n",
    "        config.max_seq_len = max(config.max_num_pairs * 3, config.max_seq_len)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset {config.dataset} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "        \n",
    "    return train_ds, eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33dd22a-e250-4d5b-9c95-bd88d8ea0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.bit_parity_trainer import BitParityTrainer\n",
    "from trainers.dyck_trainer import DyckTrainer\n",
    "from trainers.mqar_trainer import MQARTrainer\n",
    "\n",
    "def construct_trainerClass(config):\n",
    "    if config.dataset == \"bit_parity\":\n",
    "        trainer = BitParityTrainer\n",
    "    elif config.dataset == \"dyck\":\n",
    "        trainer = DyckTrainer\n",
    "    elif config.dataset == \"mqar\":\n",
    "        trainer.dataset = MQARTrainer\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Dataset {config.dataset} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80586e71-380c-417d-861d-d0a321376f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.gpt.modelgpt import ModelGPT\n",
    "from projects.lstm.basic_lstm_model import ModelLSTM\n",
    "from projects.qlstm.modelqlstm import ModelQLSTM\n",
    "\n",
    "def construct_model(config):\n",
    "    if config.model == \"gpt\":\n",
    "        model = ModelGPT(config = config)\n",
    "    elif config.model == \"lstm\":\n",
    "        model = ModelLSTM(config = config)\n",
    "    elif config.model == \"qlstm\":\n",
    "        model = ModelQLSTM(config = config)\n",
    "    else:\n",
    "        raise RuntimeError(\n",
    "            f\"Model {config.model} not supported. Please add the configuration for this dataset.\"\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc81df0-9786-4ab6-bf8e-f9fd03dc3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def set_up_seeds(config):\n",
    "    torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5d10fd-df72-4dad-b1ee-09d695583b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config):\n",
    "    \n",
    "    set_up_seeds(config)\n",
    "    train_ds, eval_ds = construct_dataset(config)\n",
    "    trainerClass = construct_trainerClass(config)\n",
    "    model = construct_model(config).to(config.device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.95), eps=1e-08)\n",
    "    logger = experiment_utils.setup_experiment(config)\n",
    "    \n",
    "    trainer = trainerClass(\n",
    "        config=config,\n",
    "        model=model,\n",
    "        train_loader=train_ds,\n",
    "        eval_loader=eval_ds,\n",
    "        optimizer=opt,\n",
    "        device=config.device,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c294b550-4913-4b78-b714-8edd3ca247e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wrapper(config):\n",
    "    import sys, os\n",
    "    sys.path.append('./common_lib')\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        config.device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        mprint(\"Cuda is not available, using CPU instead.\")\n",
    "        config.device = torch.device(\"cpu\")\n",
    "    config.project_path = os.path.join(os.getcwd(), 'projects', config.model)\n",
    "    add_exp_name(config)\n",
    "    \n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "    return run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c08d31d-3292-466d-93fa-bfa600980529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "import wandb\n",
    "from common_lib import experiment_utils\n",
    "\n",
    "def train(local=False):\n",
    "    config = load_config()\n",
    "    print('key', os.getenv(\"WANDB_API_KEY\"))\n",
    "    if local:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "\n",
    "        run(config)\n",
    "    else:\n",
    "        executor = submitit.AutoExecutor(folder=\"logs/slurm\")\n",
    "        executor.update_parameters(\n",
    "            timeout_min=60*4,\n",
    "            tasks_per_node=1,\n",
    "            #cpus_per_task=4,\n",
    "            account=\"pmlr_jobs\",\n",
    "            name=\"pmlr_training\"\n",
    "        )\n",
    "        job = executor.submit(run_wrapper, config)\n",
    "        print(f\"Submitted job with ID: {job.job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ae4bb5b-c1d2-4e79-963a-072c9aafa27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key 3585267dd9c6986318c56af0efac3ab16956dabc\n",
      "Submitted job with ID: 18599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vzarzu/miniconda3/envs/cil/lib/python3.11/site-packages/submitit/auto/auto.py:23: UserWarning: Setting 'account' is deprecated. Use 'slurm_account' instead.\n",
      "  warnings.warn(f\"Setting '{arg}' is deprecated. Use '{new_arg}' instead.\")\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "env_path = os.path.join('.', '.env')  # won't work in Jupyter\n",
    "load_dotenv()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d093180-7183-4f50-b562-881a7c6c73e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
